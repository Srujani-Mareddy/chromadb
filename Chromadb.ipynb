{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf30df1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install chromadb openai langchain tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "045884c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!wget -q https://www.dropbox.com/s/vs6ocyvpzzncvwh/new_articles.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d45eca59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download and extraction complete.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "\n",
    "# URL of the file to be downloaded\n",
    "url = \"https://www.dropbox.com/s/vs6ocyvpzzncvwh/new_articles.zip?dl=1\"\n",
    "\n",
    "# Download the file\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Unzip the file\n",
    "    with zipfile.ZipFile(io.BytesIO(response.content)) as zip_ref:\n",
    "        zip_ref.extractall(\"new_articles\")\n",
    "    print(\"Download and extraction complete.\")\n",
    "else:\n",
    "    print(f\"Failed to download file. HTTP Status Code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e60afec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dfb91f76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting unstructured\n",
      "  Obtaining dependency information for unstructured from https://files.pythonhosted.org/packages/d8/28/8debc94107c06a42cf1d3e2e62ab8642b38d2282ea3595e3038259e61acd/unstructured-0.14.4-py3-none-any.whl.metadata\n",
      "  Downloading unstructured-0.14.4-py3-none-any.whl.metadata (28 kB)\n",
      "Requirement already satisfied: chardet in c:\\users\\sruja\\anaconda3\\lib\\site-packages (from unstructured) (4.0.0)\n",
      "Requirement already satisfied: filetype in c:\\users\\sruja\\anaconda3\\lib\\site-packages (from unstructured) (1.2.0)\n",
      "Collecting python-magic (from unstructured)\n",
      "  Obtaining dependency information for python-magic from https://files.pythonhosted.org/packages/6c/73/9f872cb81fc5c3bb48f7227872c28975f998f3e7c2b1c16e95e6432bbb90/python_magic-0.4.27-py2.py3-none-any.whl.metadata\n",
      "  Downloading python_magic-0.4.27-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: lxml in c:\\users\\sruja\\anaconda3\\lib\\site-packages (from unstructured) (4.9.2)\n",
      "Requirement already satisfied: nltk in c:\\users\\sruja\\anaconda3\\lib\\site-packages (from unstructured) (3.8.1)\n",
      "Requirement already satisfied: tabulate in c:\\users\\sruja\\anaconda3\\lib\\site-packages (from unstructured) (0.8.10)\n",
      "Requirement already satisfied: requests in c:\\users\\sruja\\anaconda3\\lib\\site-packages (from unstructured) (2.31.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\sruja\\anaconda3\\lib\\site-packages (from unstructured) (4.12.2)\n",
      "Collecting emoji (from unstructured)\n",
      "  Obtaining dependency information for emoji from https://files.pythonhosted.org/packages/e6/90/20ad30babfa8f2b5ab46281d8e17bdfdbb3ac294cda14d525b9c2d958846/emoji-2.12.1-py3-none-any.whl.metadata\n",
      "  Downloading emoji-2.12.1-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: dataclasses-json in c:\\users\\sruja\\anaconda3\\lib\\site-packages (from unstructured) (0.6.6)\n",
      "Collecting python-iso639 (from unstructured)\n",
      "  Obtaining dependency information for python-iso639 from https://files.pythonhosted.org/packages/01/08/5e649cf18dec750d498c53c6c8eb1d9790752ebd50fa7f7e69cc0c277cfe/python_iso639-2024.4.27-py3-none-any.whl.metadata\n",
      "  Downloading python_iso639-2024.4.27-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting langdetect (from unstructured)\n",
      "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
      "     ---------------------------------------- 0.0/981.5 kB ? eta -:--:--\n",
      "     ------------------------------ ------ 798.7/981.5 kB 16.8 MB/s eta 0:00:01\n",
      "     ------------------------------- ----- 839.7/981.5 kB 17.6 MB/s eta 0:00:01\n",
      "     -------------------------------------- 981.5/981.5 kB 7.8 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: numpy in c:\\users\\sruja\\anaconda3\\lib\\site-packages (from unstructured) (1.24.3)\n",
      "Collecting rapidfuzz (from unstructured)\n",
      "  Obtaining dependency information for rapidfuzz from https://files.pythonhosted.org/packages/04/10/2c0ef45d4ace8dde87cfb91e48fb5c9976f8e01a57eb3230d90b82801dc5/rapidfuzz-3.9.3-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading rapidfuzz-3.9.3-cp311-cp311-win_amd64.whl.metadata (12 kB)\n",
      "Requirement already satisfied: backoff in c:\\users\\sruja\\anaconda3\\lib\\site-packages (from unstructured) (2.2.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\sruja\\anaconda3\\lib\\site-packages (from unstructured) (4.12.1)\n",
      "Collecting unstructured-client (from unstructured)\n",
      "  Obtaining dependency information for unstructured-client from https://files.pythonhosted.org/packages/b0/bc/c74937363c2657a77e4c4e105b7a004203ad53f128b5caf5dbb9dc9458d1/unstructured_client-0.22.0-py3-none-any.whl.metadata\n",
      "  Downloading unstructured_client-0.22.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: wrapt in c:\\users\\sruja\\anaconda3\\lib\\site-packages (from unstructured) (1.14.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\sruja\\anaconda3\\lib\\site-packages (from beautifulsoup4->unstructured) (2.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\sruja\\anaconda3\\lib\\site-packages (from dataclasses-json->unstructured) (3.21.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\sruja\\anaconda3\\lib\\site-packages (from dataclasses-json->unstructured) (0.9.0)\n",
      "Requirement already satisfied: six in c:\\users\\sruja\\anaconda3\\lib\\site-packages (from langdetect->unstructured) (1.16.0)\n",
      "Requirement already satisfied: click in c:\\users\\sruja\\anaconda3\\lib\\site-packages (from nltk->unstructured) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\sruja\\anaconda3\\lib\\site-packages (from nltk->unstructured) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\sruja\\anaconda3\\lib\\site-packages (from nltk->unstructured) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in c:\\users\\sruja\\anaconda3\\lib\\site-packages (from nltk->unstructured) (4.65.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sruja\\anaconda3\\lib\\site-packages (from requests->unstructured) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sruja\\anaconda3\\lib\\site-packages (from requests->unstructured) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sruja\\anaconda3\\lib\\site-packages (from requests->unstructured) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sruja\\anaconda3\\lib\\site-packages (from requests->unstructured) (2023.7.22)\n",
      "Collecting charset-normalizer<4,>=2 (from requests->unstructured)\n",
      "  Obtaining dependency information for charset-normalizer<4,>=2 from https://files.pythonhosted.org/packages/57/ec/80c8d48ac8b1741d5b963797b7c0c869335619e13d4744ca2f67fc11c6fc/charset_normalizer-3.3.2-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading charset_normalizer-3.3.2-cp311-cp311-win_amd64.whl.metadata (34 kB)\n",
      "Collecting deepdiff>=6.0 (from unstructured-client->unstructured)\n",
      "  Obtaining dependency information for deepdiff>=6.0 from https://files.pythonhosted.org/packages/18/e6/d27d37dc55dbf40cdbd665aa52844b065ac760c9a02a02265f97ea7a4256/deepdiff-7.0.1-py3-none-any.whl.metadata\n",
      "  Downloading deepdiff-7.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting jsonpath-python>=1.0.6 (from unstructured-client->unstructured)\n",
      "  Obtaining dependency information for jsonpath-python>=1.0.6 from https://files.pythonhosted.org/packages/16/8a/d63959f4eff03893a00e6e63592e3a9f15b9266ed8e0275ab77f8c7dbc94/jsonpath_python-1.0.6-py3-none-any.whl.metadata\n",
      "  Downloading jsonpath_python-1.0.6-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mypy-extensions>=1.0.0 (from unstructured-client->unstructured)\n",
      "  Obtaining dependency information for mypy-extensions>=1.0.0 from https://files.pythonhosted.org/packages/2a/e2/5d3f6ada4297caebe1a2add3b126fe800c96f56dbe5d1988a2cbe0b267aa/mypy_extensions-1.0.0-py3-none-any.whl.metadata\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: packaging>=23.1 in c:\\users\\sruja\\anaconda3\\lib\\site-packages (from unstructured-client->unstructured) (23.2)\n",
      "Collecting pypdf>=4.0 (from unstructured-client->unstructured)\n",
      "  Obtaining dependency information for pypdf>=4.0 from https://files.pythonhosted.org/packages/c9/d1/450b19bbdbb2c802f554312c62ce2a2c0d8744fe14735bc70ad2803578c7/pypdf-4.2.0-py3-none-any.whl.metadata\n",
      "  Downloading pypdf-4.2.0-py3-none-any.whl.metadata (7.4 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\sruja\\anaconda3\\lib\\site-packages (from unstructured-client->unstructured) (2.8.2)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->unstructured)\n",
      "  Obtaining dependency information for urllib3<3,>=1.21.1 from https://files.pythonhosted.org/packages/a2/73/a68704750a7679d0b6d3ad7aa8d4da8e14e151ae82e6fee774e6e0d05ec8/urllib3-2.2.1-py3-none-any.whl.metadata\n",
      "  Downloading urllib3-2.2.1-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting ordered-set<4.2.0,>=4.1.0 (from deepdiff>=6.0->unstructured-client->unstructured)\n",
      "  Obtaining dependency information for ordered-set<4.2.0,>=4.1.0 from https://files.pythonhosted.org/packages/33/55/af02708f230eb77084a299d7b08175cff006dea4f2721074b92cdb0296c0/ordered_set-4.1.0-py3-none-any.whl.metadata\n",
      "  Downloading ordered_set-4.1.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\sruja\\anaconda3\\lib\\site-packages (from click->nltk->unstructured) (0.4.6)\n",
      "Downloading unstructured-0.14.4-py3-none-any.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   -------------------------------- ------- 1.6/2.0 MB 33.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.0/2.0 MB 20.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.0/2.0 MB 18.0 MB/s eta 0:00:00\n",
      "Downloading emoji-2.12.1-py3-none-any.whl (431 kB)\n",
      "   ---------------------------------------- 0.0/431.4 kB ? eta -:--:--\n",
      "   --------------------------------------- 431.4/431.4 kB 28.1 MB/s eta 0:00:00\n",
      "Downloading python_iso639-2024.4.27-py3-none-any.whl (274 kB)\n",
      "   ---------------------------------------- 0.0/274.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 274.7/274.7 kB ? eta 0:00:00\n",
      "Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
      "Downloading rapidfuzz-3.9.3-cp311-cp311-win_amd64.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------------------------- ----------- 1.2/1.7 MB 38.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.6/1.7 MB 21.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 21.0 MB/s eta 0:00:00\n",
      "Downloading unstructured_client-0.22.0-py3-none-any.whl (28 kB)\n",
      "Downloading charset_normalizer-3.3.2-cp311-cp311-win_amd64.whl (99 kB)\n",
      "   ---------------------------------------- 0.0/99.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 99.9/99.9 kB ? eta 0:00:00\n",
      "Downloading deepdiff-7.0.1-py3-none-any.whl (80 kB)\n",
      "   ---------------------------------------- 0.0/80.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 80.8/80.8 kB ? eta 0:00:00\n",
      "Downloading jsonpath_python-1.0.6-py3-none-any.whl (7.6 kB)\n",
      "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Downloading pypdf-4.2.0-py3-none-any.whl (290 kB)\n",
      "   ---------------------------------------- 0.0/290.4 kB ? eta -:--:--\n",
      "   --------------------------------------- 290.4/290.4 kB 17.5 MB/s eta 0:00:00\n",
      "Downloading urllib3-2.2.1-py3-none-any.whl (121 kB)\n",
      "   ---------------------------------------- 0.0/121.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 121.1/121.1 kB 6.9 MB/s eta 0:00:00\n",
      "Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
      "Building wheels for collected packages: langdetect\n",
      "  Building wheel for langdetect (setup.py): started\n",
      "  Building wheel for langdetect (setup.py): finished with status 'done'\n",
      "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993253 sha256=1324dd551f784e1490a8ef4272d15538e09b60329de905acc7c851f8714d27b3\n",
      "  Stored in directory: c:\\users\\sruja\\appdata\\local\\pip\\cache\\wheels\\0a\\f2\\b2\\e5ca405801e05eb7c8ed5b3b4bcf1fcabcd6272c167640072e\n",
      "Successfully built langdetect\n",
      "Installing collected packages: urllib3, rapidfuzz, python-magic, python-iso639, pypdf, ordered-set, mypy-extensions, langdetect, jsonpath-python, emoji, charset-normalizer, deepdiff, unstructured-client, unstructured\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.26.16\n",
      "    Uninstalling urllib3-1.26.16:\n",
      "      Successfully uninstalled urllib3-1.26.16\n",
      "  Attempting uninstall: pypdf\n",
      "    Found existing installation: pypdf 3.16.4\n",
      "    Uninstalling pypdf-3.16.4:\n",
      "      Successfully uninstalled pypdf-3.16.4\n",
      "  Attempting uninstall: mypy-extensions\n",
      "    Found existing installation: mypy-extensions 0.4.3\n",
      "    Uninstalling mypy-extensions-0.4.3:\n",
      "      Successfully uninstalled mypy-extensions-0.4.3\n",
      "  Attempting uninstall: charset-normalizer\n",
      "    Found existing installation: charset-normalizer 2.0.4\n",
      "    Uninstalling charset-normalizer-2.0.4:\n",
      "      Successfully uninstalled charset-normalizer-2.0.4\n",
      "Successfully installed charset-normalizer-3.3.2 deepdiff-7.0.1 emoji-2.12.1 jsonpath-python-1.0.6 langdetect-1.0.9 mypy-extensions-1.0.0 ordered-set-4.1.0 pypdf-4.2.0 python-iso639-2024.4.27 python-magic-0.4.27 rapidfuzz-3.9.3 unstructured-0.14.4 unstructured-client-0.22.0 urllib3-2.2.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "aiohttp 3.8.3 requires charset-normalizer<3.0,>=2.0, but you have charset-normalizer 3.3.2 which is incompatible.\n",
      "botocore 1.27.59 requires urllib3<1.27,>=1.25.4, but you have urllib3 2.2.1 which is incompatible.\n",
      "python-lsp-black 1.2.1 requires black>=22.3.0, but you have black 0.0 which is incompatible.\n",
      "spacy 3.6.1 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.document_loaders import TextLoader\n",
    "!pip install unstructured\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f119a55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DirectoryLoader(\"C:/Users/sruja/2nd year/Udemy course/new_articles\",glob = \"./*.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d2a9c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "document = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4c07ad8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6a8b47f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 1000,chunk_overlap = 100)\n",
    "text = text_splitter.split_documents(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3c5bedce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Signaling that investments in the supply chain sector remain robust, Pando, a startup developing fulfillment management technologies, today announced that it raised $30 million in a Series B round, bringing its total raised to $45 million.\\n\\nIron Pillar and Uncorrelated Ventures led the round, with participation from existing investors Nexus Venture Partners, Chiratae Ventures and Next47. CEO and founder Nitin Jayakrishnan says that the new capital will be put toward expanding Pando’s global sales, marketing and delivery capabilities.\\n\\n“We will not expand into new industries or adjacent product areas,” he told TechCrunch in an email interview. “Great talent is the foundation of the business — we will continue to augment our teams at all levels of the organization. Pando is also open to exploring strategic partnerships and acquisitions with this round of funding.”'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2be324ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e52b76a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_directory = 'db'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "814aa147",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d01fe1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = Chroma.from_documents(documents=text, embedding=embeddings, persist_directory=persist_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8a218482",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sruja\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "vectordb.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1615bda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6ecbc185",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = Chroma(persist_directory=persist_directory,embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "389e1507",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectordb.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1fbb3742",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = retriver.get_relevant_documents(\"how much money did microsoft raise?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a194a662",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='April 28, 2023\\n\\nVC firms including Sequoia Capital, Andreessen Horowitz, Thrive and K2 Global are picking up new shares, according to documents seen by TechCrunch. A source tells us Founders Fund is also investing. Altogether the VCs have put in just over $300 million at a valuation of $27 billion to $29 billion. This is separate to a big investment from Microsoft announced earlier this year, a person familiar with the development told TechCrunch, which closed in January. The size of Microsoft’s investment is believed to be around $10 billion, a figure we confirmed with our source.\\n\\nApril 25, 2023\\n\\nCalled ChatGPT Business, OpenAI describes the forthcoming offering as “for professionals who need more control over their data as well as enterprises seeking to manage their end users.”', metadata={'source': 'C:\\\\Users\\\\sruja\\\\2nd year\\\\Udemy course\\\\new_articles\\\\05-03-chatgpt-everything-you-need-to-know-about-the-ai-powered-chatbot.txt'}),\n",
       " Document(page_content='Partners of 3one4 Capital, a venture capital firm in India, recently went on a road show to raise a new fund. Within two and a half months, at the height of the worsening global economy, they had secured $200 million. It’s the fourth marquee fund for the Bengaluru-headquartered fund, whose portfolio includes four unicorn startups.\\n\\nThe fund, sixth overall for 3one4 Capital, was oversubscribed to $250 million but the firm is accepting only $200 million to keep itself lean and disciplined, said Pranav Pai, co-founder and partner at 3one4 Capital. The firm’s decision to limit the fund size is emblematic of its strategic choices, which have set it apart from other Indian venture firms.', metadata={'source': 'C:\\\\Users\\\\sruja\\\\2nd year\\\\Udemy course\\\\new_articles\\\\05-07-3one4-capital-driven-by-contrarian-bets-raises-200-million-new-fund.txt'}),\n",
       " Document(page_content='Manish Singh reported that Paytm, India’s leading mobile payments firm, reported a 13.2% surge in revenue to $285.7 million in the quarter ending March and pared its loss by 57% to $20.5 million “in a sharp turnaround for the company that is increasingly trying to become profitable following a tremulous year and a half after its public debut.” More here.\\n\\nMore headlines\\n\\nApple and fintechs like Robinhood chase yield-hungry depositors as Fed rate hikes continue. Similarly, Arta Finance, a company providing access to alternative assets, debuted the Harvest Treasuries AI-Managed Portfolio, which offers a 4.62% APY (annual percentage yield), and Wealthfront’s cash account now offers 4.55% for all clients and 5.05% APY for clients who refer a friend.\\n\\nFintech projected to become a $1.5 trillion industry by 2030, according to a new report from Boston Consulting Group and QED Investors\\n\\nOpendoor tech earnings beat by $0.77, revenue topped estimates', metadata={'source': 'C:\\\\Users\\\\sruja\\\\2nd year\\\\Udemy course\\\\new_articles\\\\05-07-fintech-space-continues-to-be-competitive-and-drama-filled.txt'}),\n",
       " Document(page_content='The company had been experimenting since last year with the new feed, which features content creators by influencers. DoorDash revenue was up 40% YoY in Q1, reaching $2.04 billion, beating estimates of $1.93 billion. Its net loss also declined 3% to $162 million and orders were up 27% to 512 million.\\n\\nEtc.\\n\\nAmazon rolled out a Matter update for Alexa that includes support for Thread, setup on iOS, and a new version of its Works with Alexa program.\\n\\nand a new version of its Works with Alexa program. Match Group posted a Q1 earnings miss with revenue down by 1% YoY to $787 million and paying users down 3% to 15.9 million. The company, however, said it’s “very possible” the recent Apple-Epic court decision could result in App Store fee relief.\\n\\nMedtech startup Healthy.io, which provides urine analysis through a mobile app, is laying off a third of its staff, or around 70 people. The company had just raised $50 million in Series D funding.', metadata={'source': 'C:\\\\Users\\\\sruja\\\\2nd year\\\\Udemy course\\\\new_articles\\\\05-06-this-week-in-apps-apple-and-google-team-up-on-trackers-google-i-o-preview-apps-hit-newfronts.txt'})]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "373c0ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "43a5fd91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sruja\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "llm=OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e7f29c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=retriever, return_source_documents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "673b4605",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_llm_response(llm_response):\n",
    "    print(llm_response['result'])\n",
    "    print('\\n\\nSources:')\n",
    "    for source in llm_response['source_documents']:\n",
    "        print(source.metadata['source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a3143213",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sruja\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " $10 billion\n",
      "\n",
      "\n",
      "Sources:\n",
      "C:\\Users\\sruja\\2nd year\\Udemy course\\new_articles\\05-03-chatgpt-everything-you-need-to-know-about-the-ai-powered-chatbot.txt\n",
      "C:\\Users\\sruja\\2nd year\\Udemy course\\new_articles\\05-07-3one4-capital-driven-by-contrarian-bets-raises-200-million-new-fund.txt\n",
      "C:\\Users\\sruja\\2nd year\\Udemy course\\new_articles\\05-07-fintech-space-continues-to-be-competitive-and-drama-filled.txt\n",
      "C:\\Users\\sruja\\2nd year\\Udemy course\\new_articles\\05-06-this-week-in-apps-apple-and-google-team-up-on-trackers-google-i-o-preview-apps-hit-newfronts.txt\n"
     ]
    }
   ],
   "source": [
    "query = \"how much money did microsoft raise?\"\n",
    "llm_response = qa_chain(query)\n",
    "process_llm_response(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4909e10a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f2ca0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bd4590",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616d22ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ef0ef8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d864d5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
